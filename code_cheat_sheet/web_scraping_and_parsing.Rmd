---
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    theme: cosmo
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rvest)
```

<h1>HTML Scraping and Parsing</h1><ol type="I">
Web scraping and parsing was(and will be) an important part of my research interest. There are many useful packages in `R` that makes web scraping simple: `rvest`, `XML`, `RCurl`, `curl`, `RSelenium`, and etc. 

<h2><li>Using the <a href="https://cran.r-project.org/web/packages/rvest/rvest.pdf">`rvest` package</a></li></h2><ol type="1">
```{r, eval=F}
install.packages("rvest") #if you haven't installed `rvest` yet
require(rvest) #load the `rvest` package
```

<h3><li>`read_html`</li></h3>
read_html(*url*)

Argument
*url*: A url string

```{r, tidy=TRUE, comment=""}
read_html("http://TekSong.github.io/")
```

<h3><li>`html_nodes`</li></h3><ol type="a">

<h4><li>Single Node Set</li></h4>
* Usage: Parse `HTML` documents using XPath or CSS selector.
html\_nodes(*html\_doc*, *css*, *xpath*)

* Argument
*html\_doc*: A `HTML` document or a node set
*css*: css selector
*xpath*: xpath selector

* e.g.:
read_html(*some\_url*) %>%<br>
  html_nodes(xpath="//b")
Extracts all bold font text using the xpath selector //b.

read_html(*some\_url*) %>%<br>
  html_nodes(xpath='//div [@id="*something*"])

read_html(*some\_url*) %>%<br>
  html_nodes("center")
Extract using css selector center

* chain subsetting
read_html(*some\_url*) %>%<br>
  html_nodes("center") %>%<br>
  html_nodes("font")
  
```{r, comment=""}
read_html("https://jeffsong9.github.io/") %>%
  html_nodes(xpath="//div") %>%
  head(5)
```
  
  
cf) `html_node`

<h4><li>Multiple Node Sets</li></h4>
One may be interested in extracting multiple node sets. I find it convenient to save all XPath queries in a vector and use the `lapply` function in conjunction with the `html_nodes` function.


```{r, comment=""}
paths=c(profile='//div [@class="profile-info-mod profile-essentials"]',
        side_bar='//div [@class="floating-sidebar-float"]')

lapply(paths, function(x) read_html("https://jeffsong9.github.io/") %>%
  html_nodes(xpath=x))
```




</ol><!--html_nodes-->

<h3><li>`html_attr`</li></h3>
Usage: Extrac attributes with a given name
html_attr(*html\_doc*, *name*)

Arguments:
*html node*: A`HTML` document or a node set
*name*: Name of attribute to extract

e.g.
read_html(*some\_url*) %>%<br>
  html_nodes(xpath="//a") %>%<br>
  html_attr(name="href")

```{r, comment=""}
read_html("https://jeffsong9.github.io/") %>%
  html_nodes(xpath="//img [@class='photo']")
```

```{r, comment=""}
read_html("https://jeffsong9.github.io/") %>%
  html_nodes(xpath="//img [@class='photo']") %>%
  html_attr(name="src")
```

cf) html_attrs


</ol><!--rvest package-->
<h2><li>More to be updated</li></h2><ol type="1">
<h3><li>How to scrape HTML with javascript embedded </li></h3>
</ol>
</ol><!--HTML Scraping and parsing-->
